{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml import preprocessing\n",
    "import dask_ml.metrics as metrics\n",
    "\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask_ml.xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=8)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_rd = dd.read_csv(paths.processed + \"/EngineeredTrainData/*.part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_rd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_rd = sg_rd.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-texture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sg_rd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerating all of the possible training columns\n",
    "XR_cols = sg_rd.columns[4:40]\n",
    "XD_cols = sg_rd.columns[40:]\n",
    "\n",
    "# Chosen training columns\n",
    "P_cols = [\"Ast_D\", \"Blk_D\", \"FGP_D\", \"OppAst_D\", \"OppDR_D\",\n",
    "          \"OppFGP_D\", \"OppRank_D\", \"OppScore_R\", \"Rank_D\", \"Score_R\", \"TO_R\", \"Wins_D\", \"RankedWins_D\"]\n",
    "\n",
    "# Specifying outcome column\n",
    "Y_cols = sg_rd.columns[3]\n",
    "\n",
    "X_df = sg_rd[P_cols]\n",
    "Y_df = sg_rd[Y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-postage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-sandwich",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.to_dask_array(lengths=True)\n",
    "Y = Y_df.to_dask_array(lengths=True)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_cv_train, X_cv_test, Y_cv_train, Y_cv_test = train_test_split(X, Y, train_size=0.8, random_state=0)\n",
    "\n",
    "# Persisting data for efficiency when doing analysis\n",
    "X_cv_test.persist()\n",
    "Y_cv_test.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats (model, X_test, Y_test):\n",
    "    prob = model.predict_proba(X_test)\n",
    "    print(\"Log-Loss: \", metrics.log_loss(Y_test, prob).compute())\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(Y_test, preds))\n",
    "    \n",
    "def getStatsSK (model, X_test, Y_test):\n",
    "    prob = model.predict_proba(X_test)\n",
    "    print(\"Log-Loss: \", metrics.log_loss(Y_test, prob))\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(Y_test, preds))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_cv_train, Y_cv_train)\n",
    "getStats(lr, X_cv_test, Y_cv_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression()\n",
    "lr_final.fit(X, Y)\n",
    "pickle.dump(lr_final, open(paths.models + \"/lr_final.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(max_depth=4)\n",
    "xgbc.fit(X_cv_train, Y_cv_train)\n",
    "\n",
    "getStats(xgbc, X_cv_test, Y_cv_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_final = XGBClassifier(max_depth=4)\n",
    "xgbc_final.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbc_final, open(paths.models + \"/xgb_final.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-female",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
