{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import dask_ml.preprocessing as preprocessing\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask_ml.xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import paths\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spin up local cluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dd.read_csv(paths.processed + \"/EngineeredTestDataSubmission1/*.part\")\n",
    "model = pickle.load(open(paths.models + \"/lr_final.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which columns will be used for model predictions\n",
    "which_cols = [\"Ast_D\", \"Blk_D\", \"FGP_D\", \"OppAst_D\", \"OppDR_D\",\n",
    "          \"OppFGP_D\", \"OppRank_D\", \"OppScore_R\", \"Rank_D\", \"Score_R\", \"TO_R\", \"Wins_D\", \"RankedWins_D\"]\n",
    "\n",
    "X = test_data[which_cols].to_dask_array(lengths=True)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-legislation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the predictions with team IDs\n",
    "submission_df = test_data[\"id\"].to_dask_array(lengths=True)\n",
    "submission_df = dd.from_dask_array(submission_df, columns=[\"id\"])\n",
    "submission_df[\"Result\"] = predictions\n",
    "submission_df = submission_df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write ID-Predictions to file\n",
    "submission_df.to_csv(paths.processed + \"/Submission1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-foster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
